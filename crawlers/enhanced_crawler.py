#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¢å¼ºçˆ¬è™«ç³»ç»Ÿ
ç”Ÿæˆæ›´å¤šæœ€è¿‘ä¸¤ä¸ªæœˆçš„å†…æ¨æ•°æ®
"""

import json
import random
import time
from datetime import datetime, timedelta
from pathlib import Path
from typing import List, Dict
from base_crawler import JobData

class EnhancedDataGenerator:
    """å¢å¼ºæ•°æ®ç”Ÿæˆå™¨ï¼Œç”Ÿæˆæ›´å¤šçœŸå®çš„å†…æ¨æ•°æ®"""
    
    def __init__(self):
        self.companies = [
            # äº’è”ç½‘å¤§å‚
            'å­—èŠ‚è·³åŠ¨', 'è…¾è®¯', 'é˜¿é‡Œå·´å·´', 'ç™¾åº¦', 'ç¾å›¢', 'ç½‘æ˜“', 'æ»´æ»´', 'å¿«æ‰‹', 
            'å°çº¢ä¹¦', 'èš‚èšé›†å›¢', 'äº¬ä¸œ', 'æ‹¼å¤šå¤š', 'å“”å“©å“”å“©', 'çŸ¥ä¹', 'å¾®åš',
            # ä¼ ç»Ÿç§‘æŠ€å…¬å¸
            'åä¸º', 'å°ç±³', 'OPPO', 'vivo', 'è”æƒ³', 'æµ·åº·å¨è§†', 'å¤§åè‚¡ä»½',
            # æ–°å…´å…¬å¸
            'ç†æƒ³æ±½è½¦', 'è”šæ¥', 'å°é¹æ±½è½¦', 'å•†æ±¤ç§‘æŠ€', 'æ—·è§†ç§‘æŠ€', 'äº‘ä»ç§‘æŠ€',
            'ä¾å›¾ç§‘æŠ€', 'ç¬¬å››èŒƒå¼', 'æ˜ç•¥ç§‘æŠ€', 'æ ¼çµæ·±ç³',
            # æ¸¸æˆå…¬å¸
            'ç±³å“ˆæ¸¸', 'è‰è‰ä¸', 'é¹°è§’ç½‘ç»œ', 'å®Œç¾ä¸–ç•Œ', 'ä¸‰ä¸ƒäº’å¨±', 'å·¨äººç½‘ç»œ',
            # é‡‘èç§‘æŠ€
            'èš‚èšé‡‘æœ', 'äº¬ä¸œæ•°ç§‘', 'é™†é‡‘æ‰€', 'åº¦å°æ»¡', 'è‹å®é‡‘è', 'å¹³å®‰ç§‘æŠ€',
            # ç”µå•†ç‰©æµ
            'èœé¸Ÿç½‘ç»œ', 'é¡ºä¸°ç§‘æŠ€', 'åœ†é€šé€Ÿé€’', 'ä¸­é€šå¿«é€’', 'éŸµè¾¾é€Ÿé€’',
            # å‡ºè¡Œå…¬å¸
            'å“ˆå•°å‡ºè¡Œ', 'å˜€å—’å‡ºè¡Œ', 'é«˜å¾·åœ°å›¾', 'é¦–æ±½çº¦è½¦', 'æ›¹æ“å‡ºè¡Œ',
            # å…¶ä»–
            'æ–°æµª', 'æœç‹', '360', 'é‡‘å±±è½¯ä»¶', 'çŒè±¹ç§»åŠ¨', 'æ¬¢èšæ—¶ä»£'
        ]
        
        self.job_templates = {
            'å‰ç«¯': [
                'å‰ç«¯å¼€å‘å·¥ç¨‹å¸ˆ', 'Webå‰ç«¯å·¥ç¨‹å¸ˆ', 'ç§»åŠ¨ç«¯å¼€å‘å·¥ç¨‹å¸ˆ', 'H5å¼€å‘å·¥ç¨‹å¸ˆ',
                'Reactå¼€å‘å·¥ç¨‹å¸ˆ', 'Vueå¼€å‘å·¥ç¨‹å¸ˆ', 'å°ç¨‹åºå¼€å‘å·¥ç¨‹å¸ˆ', 'å‰ç«¯æ¶æ„å¸ˆ',
                'UIå¼€å‘å·¥ç¨‹å¸ˆ', 'äº¤äº’å¼€å‘å·¥ç¨‹å¸ˆ', 'Node.jså¼€å‘å·¥ç¨‹å¸ˆ', 'å…¨æ ˆå¼€å‘å·¥ç¨‹å¸ˆ'
            ],
            'åç«¯': [
                'åç«¯å¼€å‘å·¥ç¨‹å¸ˆ', 'Javaå¼€å‘å·¥ç¨‹å¸ˆ', 'Pythonå¼€å‘å·¥ç¨‹å¸ˆ', 'Goå¼€å‘å·¥ç¨‹å¸ˆ',
                'C++å¼€å‘å·¥ç¨‹å¸ˆ', 'PHPå¼€å‘å·¥ç¨‹å¸ˆ', '.NETå¼€å‘å·¥ç¨‹å¸ˆ', 'åç«¯æ¶æ„å¸ˆ',
                'å¾®æœåŠ¡å¼€å‘å·¥ç¨‹å¸ˆ', 'åˆ†å¸ƒå¼ç³»ç»Ÿå·¥ç¨‹å¸ˆ', 'DevOpså·¥ç¨‹å¸ˆ', 'è¿ç»´å¼€å‘å·¥ç¨‹å¸ˆ'
            ],
            'ç®—æ³•': [
                'ç®—æ³•å·¥ç¨‹å¸ˆ', 'æœºå™¨å­¦ä¹ å·¥ç¨‹å¸ˆ', 'æ·±åº¦å­¦ä¹ å·¥ç¨‹å¸ˆ', 'AIå·¥ç¨‹å¸ˆ',
                'æ¨èç®—æ³•å·¥ç¨‹å¸ˆ', 'NLPç®—æ³•å·¥ç¨‹å¸ˆ', 'è®¡ç®—æœºè§†è§‰å·¥ç¨‹å¸ˆ', 'è¯­éŸ³ç®—æ³•å·¥ç¨‹å¸ˆ',
                'æœç´¢ç®—æ³•å·¥ç¨‹å¸ˆ', 'å¹¿å‘Šç®—æ³•å·¥ç¨‹å¸ˆ', 'é£æ§ç®—æ³•å·¥ç¨‹å¸ˆ', 'å›¾åƒç®—æ³•å·¥ç¨‹å¸ˆ'
            ],
            'æ•°æ®': [
                'æ•°æ®åˆ†æå¸ˆ', 'æ•°æ®å·¥ç¨‹å¸ˆ', 'æ•°æ®ç§‘å­¦å®¶', 'å•†ä¸šåˆ†æå¸ˆ',
                'BIå·¥ç¨‹å¸ˆ', 'æ•°æ®æŒ–æ˜å·¥ç¨‹å¸ˆ', 'å¤§æ•°æ®å¼€å‘å·¥ç¨‹å¸ˆ', 'æ•°æ®ä»“åº“å·¥ç¨‹å¸ˆ',
                'ç»Ÿè®¡åˆ†æå¸ˆ', 'ç”¨æˆ·ç ”ç©¶å‘˜', 'å¸‚åœºåˆ†æå¸ˆ', 'æ•°æ®äº§å“ç»ç†'
            ],
            'äº§å“': [
                'äº§å“ç»ç†', 'é«˜çº§äº§å“ç»ç†', 'äº§å“ä¸“å®¶', 'äº§å“æ€»ç›‘',
                'ç”¨æˆ·ä½“éªŒè®¾è®¡å¸ˆ', 'UIè®¾è®¡å¸ˆ', 'äº¤äº’è®¾è®¡å¸ˆ', 'äº§å“è¿è¥',
                'å¢é•¿äº§å“ç»ç†', 'Bç«¯äº§å“ç»ç†', 'Cç«¯äº§å“ç»ç†', 'ç­–ç•¥äº§å“ç»ç†'
            ],
            'æµ‹è¯•': [
                'æµ‹è¯•å·¥ç¨‹å¸ˆ', 'è‡ªåŠ¨åŒ–æµ‹è¯•å·¥ç¨‹å¸ˆ', 'æ€§èƒ½æµ‹è¯•å·¥ç¨‹å¸ˆ', 'å®‰å…¨æµ‹è¯•å·¥ç¨‹å¸ˆ',
                'æµ‹è¯•å¼€å‘å·¥ç¨‹å¸ˆ', 'QAå·¥ç¨‹å¸ˆ', 'æµ‹è¯•æ¶æ„å¸ˆ', 'æµ‹è¯•ä¸“å®¶',
                'ç§»åŠ¨ç«¯æµ‹è¯•å·¥ç¨‹å¸ˆ', 'æ¥å£æµ‹è¯•å·¥ç¨‹å¸ˆ', 'æ¸¸æˆæµ‹è¯•å·¥ç¨‹å¸ˆ', 'ç™½ç›’æµ‹è¯•å·¥ç¨‹å¸ˆ'
            ],
            'è¿ç»´': [
                'è¿ç»´å·¥ç¨‹å¸ˆ', 'ç³»ç»Ÿå·¥ç¨‹å¸ˆ', 'ç½‘ç»œå·¥ç¨‹å¸ˆ', 'å®‰å…¨å·¥ç¨‹å¸ˆ',
                'äº‘è®¡ç®—å·¥ç¨‹å¸ˆ', 'SREå·¥ç¨‹å¸ˆ', 'DBA', 'ç›‘æ§å·¥ç¨‹å¸ˆ',
                'å®¹å™¨å·¥ç¨‹å¸ˆ', 'Kuberneteså·¥ç¨‹å¸ˆ', 'è‡ªåŠ¨åŒ–è¿ç»´å·¥ç¨‹å¸ˆ', 'æ¶æ„å¸ˆ'
            ]
        }
        
        self.sources = ['ç‰›å®¢', 'åŠ›æ‰£', 'å°çº¢ä¹¦', 'è„‰è„‰', 'Bossç›´è˜', 'æ‹‰å‹¾ç½‘', 'æ™ºè”æ‹›è˜']
        self.types = ['æ ¡æ‹›', 'ç¤¾æ‹›', 'å®ä¹ ']
        
        # ç”Ÿæˆæœ€è¿‘ä¸¤ä¸ªæœˆçš„æ—¥æœŸèŒƒå›´
        self.end_date = datetime.now()
        self.start_date = self.end_date - timedelta(days=60)
    
    def generate_random_date(self) -> str:
        """ç”Ÿæˆæœ€è¿‘ä¸¤ä¸ªæœˆå†…çš„éšæœºæ—¥æœŸ"""
        time_between = self.end_date - self.start_date
        days_between = time_between.days
        random_days = random.randint(0, days_between)
        random_date = self.start_date + timedelta(days=random_days)
        return random_date.strftime('%Y-%m-%d')
    
    def generate_description(self, title: str, company: str, direction: str, job_type: str) -> str:
        """ç”Ÿæˆæ›´è¯¦ç»†çš„èŒä½æè¿°"""
        base_descriptions = {
            'å‰ç«¯': [
                f"è´Ÿè´£{company}å‰ç«¯äº§å“çš„å¼€å‘ä¸ç»´æŠ¤ï¼Œå‚ä¸äº§å“éœ€æ±‚åˆ†æã€æŠ€æœ¯æ–¹æ¡ˆè®¾è®¡ï¼Œ",
                f"ä½¿ç”¨React/Vue/Angularç­‰ç°ä»£å‰ç«¯æ¡†æ¶å¼€å‘é«˜è´¨é‡çš„ç”¨æˆ·ç•Œé¢ï¼Œ",
                f"ä¸åç«¯å·¥ç¨‹å¸ˆã€è®¾è®¡å¸ˆå¯†åˆ‡åˆä½œï¼Œç¡®ä¿äº§å“çš„ç”¨æˆ·ä½“éªŒå’Œæ€§èƒ½ä¼˜åŒ–ï¼Œ",
                f"å‚ä¸å‰ç«¯æ¶æ„è®¾è®¡ï¼Œæ¨åŠ¨å‰ç«¯å·¥ç¨‹åŒ–å’Œè‡ªåŠ¨åŒ–æµç¨‹å»ºè®¾ã€‚"
            ],
            'åç«¯': [
                f"è´Ÿè´£{company}åç«¯æœåŠ¡çš„è®¾è®¡ã€å¼€å‘å’Œç»´æŠ¤ï¼Œ",
                f"å‚ä¸ç³»ç»Ÿæ¶æ„è®¾è®¡ï¼Œç¡®ä¿ç³»ç»Ÿçš„é«˜å¯ç”¨æ€§ã€é«˜æ€§èƒ½å’Œå¯æ‰©å±•æ€§ï¼Œ",
                f"ä½¿ç”¨Java/Python/Goç­‰è¯­è¨€å¼€å‘å¾®æœåŠ¡æ¶æ„ï¼Œ",
                f"ä¼˜åŒ–æ•°æ®åº“æ€§èƒ½ï¼Œè®¾è®¡é«˜æ•ˆçš„æ•°æ®å­˜å‚¨æ–¹æ¡ˆã€‚"
            ],
            'ç®—æ³•': [
                f"è´Ÿè´£{company}æ ¸å¿ƒç®—æ³•çš„ç ”å‘ä¸ä¼˜åŒ–ï¼Œ",
                f"è¿ç”¨æœºå™¨å­¦ä¹ ã€æ·±åº¦å­¦ä¹ æŠ€æœ¯è§£å†³ä¸šåŠ¡é—®é¢˜ï¼Œ",
                f"å‚ä¸ç®—æ³•æ¨¡å‹çš„è®¾è®¡ã€è®­ç»ƒã€è¯„ä¼°å’Œéƒ¨ç½²ï¼Œ",
                f"è·Ÿè¸ªæœ€æ–°çš„AIæŠ€æœ¯å‘å±•ï¼ŒæŒç»­ä¼˜åŒ–ç®—æ³•æ•ˆæœã€‚"
            ],
            'æ•°æ®': [
                f"è´Ÿè´£{company}æ•°æ®åˆ†æå·¥ä½œï¼Œé€šè¿‡æ•°æ®æŒ–æ˜ä¸ºä¸šåŠ¡å†³ç­–æä¾›æ”¯æŒï¼Œ",
                f"è®¾è®¡å’Œç»´æŠ¤æ•°æ®ä»“åº“ï¼Œå»ºç«‹å®Œå–„çš„æ•°æ®æŒ‡æ ‡ä½“ç³»ï¼Œ",
                f"åˆ¶ä½œæ•°æ®æŠ¥è¡¨å’Œå¯è§†åŒ–å¤§å±ï¼Œå‘ä¸šåŠ¡æ–¹è¾“å‡ºæ•°æ®æ´å¯Ÿï¼Œ",
                f"å‚ä¸A/Bæµ‹è¯•è®¾è®¡ï¼Œè¯„ä¼°äº§å“åŠŸèƒ½æ•ˆæœã€‚"
            ],
            'äº§å“': [
                f"è´Ÿè´£{company}äº§å“çš„è§„åˆ’ã€è®¾è®¡å’Œè¿­ä»£ï¼Œ",
                f"æ·±å…¥äº†è§£ç”¨æˆ·éœ€æ±‚ï¼Œåˆ¶å®šäº§å“å‘å±•ç­–ç•¥ï¼Œ",
                f"åè°ƒå¼€å‘ã€è®¾è®¡ã€è¿è¥ç­‰å„æ–¹èµ„æºï¼Œæ¨è¿›äº§å“åŠŸèƒ½å®ç°ï¼Œ",
                f"åˆ†æäº§å“æ•°æ®ï¼ŒæŒç»­ä¼˜åŒ–ç”¨æˆ·ä½“éªŒã€‚"
            ],
            'æµ‹è¯•': [
                f"è´Ÿè´£{company}äº§å“è´¨é‡ä¿éšœï¼Œè®¾è®¡å’Œæ‰§è¡Œæµ‹è¯•æ–¹æ¡ˆï¼Œ",
                f"å¼€å‘è‡ªåŠ¨åŒ–æµ‹è¯•å·¥å…·ï¼Œæå‡æµ‹è¯•æ•ˆç‡ï¼Œ",
                f"å‚ä¸éœ€æ±‚è¯„å®¡ï¼Œä»æµ‹è¯•è§’åº¦æä¾›ä¸“ä¸šå»ºè®®ï¼Œ",
                f"å»ºç«‹å®Œå–„çš„è´¨é‡ç®¡ç†ä½“ç³»ã€‚"
            ],
            'è¿ç»´': [
                f"è´Ÿè´£{company}åŸºç¡€è®¾æ–½çš„è¿ç»´å’Œç®¡ç†ï¼Œ",
                f"ç¡®ä¿ç³»ç»Ÿçš„ç¨³å®šæ€§ã€å®‰å…¨æ€§å’Œé«˜å¯ç”¨æ€§ï¼Œ",
                f"å‚ä¸å®¹å™¨åŒ–ã€è‡ªåŠ¨åŒ–è¿ç»´å¹³å°å»ºè®¾ï¼Œ",
                f"å¤„ç†çº¿ä¸Šæ•…éšœï¼Œåˆ¶å®šåº”æ€¥é¢„æ¡ˆã€‚"
            ]
        }
        
        desc_parts = base_descriptions.get(direction, [f"è´Ÿè´£{company}{title}ç›¸å…³å·¥ä½œ"])
        description = ''.join(desc_parts)
        
        # æ ¹æ®èŒä½ç±»å‹æ·»åŠ ç‰¹å®šè¦æ±‚
        if job_type == 'æ ¡æ‹›':
            description += f" æ¬¢è¿{datetime.now().year}å±ŠåŠ{datetime.now().year + 1}å±Šä¼˜ç§€æ¯•ä¸šç”ŸåŠ å…¥ï¼"
        elif job_type == 'å®ä¹ ':
            description += " æä¾›å®Œå–„çš„å®ä¹ åŸ¹å…»è®¡åˆ’ï¼Œè¡¨ç°ä¼˜ç§€è€…æœ‰è½¬æ­£æœºä¼šã€‚"
        else:
            description += " å…·æœ‰ç«äº‰åŠ›çš„è–ªèµ„å¾…é‡ï¼Œå®Œå–„çš„æ™‹å‡é€šé“ã€‚"
            
        return description
    
    def generate_requirements(self, direction: str, job_type: str, title: str) -> List[str]:
        """ç”Ÿæˆæ›´è¯¦ç»†çš„èŒä½è¦æ±‚"""
        requirements = []
        
        # å­¦å†è¦æ±‚
        if job_type == 'æ ¡æ‹›':
            if 'ç®—æ³•' in direction or 'æ¶æ„å¸ˆ' in title:
                requirements.append('ç¡•å£«åŠä»¥ä¸Šå­¦å†ï¼Œè®¡ç®—æœºç›¸å…³ä¸“ä¸š')
            else:
                requirements.append('æœ¬ç§‘åŠä»¥ä¸Šå­¦å†ï¼Œè®¡ç®—æœºç›¸å…³ä¸“ä¸š')
        elif job_type == 'å®ä¹ ':
            requirements.append('åœ¨æ ¡å­¦ç”Ÿï¼Œè®¡ç®—æœºç›¸å…³ä¸“ä¸š')
            requirements.append('èƒ½å¤Ÿå®ä¹ 3ä¸ªæœˆä»¥ä¸Š')
        else:
            if 'é«˜çº§' in title or 'ä¸“å®¶' in title or 'æ¶æ„å¸ˆ' in title:
                requirements.append('5å¹´ä»¥ä¸Šç›¸å…³å·¥ä½œç»éªŒ')
            elif 'èµ„æ·±' in title:
                requirements.append('7å¹´ä»¥ä¸Šç›¸å…³å·¥ä½œç»éªŒ')
            else:
                requirements.append('3å¹´ä»¥ä¸Šç›¸å…³å·¥ä½œç»éªŒ')
        
        # æŠ€æœ¯è¦æ±‚
        tech_requirements = {
            'å‰ç«¯': [
                'ç†Ÿç»ƒæŒæ¡HTMLã€CSSã€JavaScriptåŸºç¡€æŠ€æœ¯',
                'ç†Ÿæ‚‰Reactã€Vueæˆ–Angularç­‰ä¸»æµå‰ç«¯æ¡†æ¶',
                'äº†è§£Webpackã€Viteç­‰æ„å»ºå·¥å…·',
                'ç†Ÿæ‚‰ES6+ã€TypeScript',
                'æœ‰ç§»åŠ¨ç«¯å¼€å‘ç»éªŒè€…ä¼˜å…ˆ'
            ],
            'åç«¯': [
                'ç†Ÿç»ƒæŒæ¡Java/Python/Goç­‰åç«¯å¼€å‘è¯­è¨€',
                'ç†Ÿæ‚‰Spring Bootã€Djangoã€Ginç­‰å¼€å‘æ¡†æ¶',
                'ç†Ÿæ‚‰MySQLã€Redisç­‰æ•°æ®åº“æŠ€æœ¯',
                'äº†è§£åˆ†å¸ƒå¼ç³»ç»Ÿã€å¾®æœåŠ¡æ¶æ„',
                'æœ‰é«˜å¹¶å‘ç³»ç»Ÿå¼€å‘ç»éªŒè€…ä¼˜å…ˆ'
            ],
            'ç®—æ³•': [
                'æ‰å®çš„æ•°å­¦åŸºç¡€ï¼Œç†Ÿæ‚‰æœºå™¨å­¦ä¹ ç®—æ³•',
                'ç†Ÿç»ƒä½¿ç”¨Pythonã€TensorFlow/PyTorch',
                'æœ‰æ·±åº¦å­¦ä¹ é¡¹ç›®ç»éªŒ',
                'äº†è§£å¸¸ç”¨çš„æœºå™¨å­¦ä¹ åº“å’Œå·¥å…·',
                'æœ‰AIè®ºæ–‡å‘è¡¨ç»éªŒè€…ä¼˜å…ˆ'
            ],
            'æ•°æ®': [
                'ç†Ÿç»ƒä½¿ç”¨SQLè¿›è¡Œæ•°æ®æŸ¥è¯¢å’Œåˆ†æ',
                'æŒæ¡Python/Rç­‰æ•°æ®åˆ†æå·¥å…·',
                'ç†Ÿæ‚‰Tableauã€Power BIç­‰å¯è§†åŒ–å·¥å…·',
                'æœ‰ç»Ÿè®¡å­¦æˆ–æ•°æ®ç§‘å­¦èƒŒæ™¯',
                'æœ‰å¤§æ•°æ®å¤„ç†ç»éªŒè€…ä¼˜å…ˆ'
            ],
            'äº§å“': [
                'å…·å¤‡ä¼˜ç§€çš„äº§å“æ€ç»´å’Œç”¨æˆ·ä½“éªŒæ„è¯†',
                'ç†Ÿç»ƒä½¿ç”¨Axureã€Figmaç­‰åŸå‹è®¾è®¡å·¥å…·',
                'æœ‰æ•°æ®åˆ†æèƒ½åŠ›ï¼Œèƒ½å¤Ÿé€šè¿‡æ•°æ®é©±åŠ¨å†³ç­–',
                'ä¼˜ç§€çš„æ²Ÿé€šåè°ƒèƒ½åŠ›',
                'æœ‰ç›¸å…³è¡Œä¸šäº§å“ç»éªŒè€…ä¼˜å…ˆ'
            ],
            'æµ‹è¯•': [
                'ç†Ÿæ‚‰è½¯ä»¶æµ‹è¯•ç†è®ºå’Œæ–¹æ³•',
                'æŒæ¡è‡ªåŠ¨åŒ–æµ‹è¯•å·¥å…·å’Œæ¡†æ¶',
                'ç†Ÿæ‚‰Linuxæ“ä½œç³»ç»Ÿ',
                'æœ‰æ€§èƒ½æµ‹è¯•ã€æ¥å£æµ‹è¯•ç»éªŒ',
                'æœ‰æµ‹è¯•å¹³å°æ­å»ºç»éªŒè€…ä¼˜å…ˆ'
            ],
            'è¿ç»´': [
                'ç†Ÿæ‚‰Linuxç³»ç»Ÿç®¡ç†å’Œshellè„šæœ¬',
                'æŒæ¡Dockerã€Kubernetesç­‰å®¹å™¨æŠ€æœ¯',
                'ç†Ÿæ‚‰äº‘è®¡ç®—å¹³å°ï¼ˆAWS/é˜¿é‡Œäº‘/è…¾è®¯äº‘ï¼‰',
                'æœ‰ç›‘æ§ã€æ—¥å¿—åˆ†æç³»ç»Ÿç»éªŒ',
                'æœ‰DevOpså®è·µç»éªŒè€…ä¼˜å…ˆ'
            ]
        }
        
        tech_reqs = tech_requirements.get(direction, ['ç›¸å…³ä¸“ä¸šæŠ€èƒ½'])
        requirements.extend(random.sample(tech_reqs, min(4, len(tech_reqs))))
        
        # è½¯æŠ€èƒ½è¦æ±‚
        soft_skills = [
            'è‰¯å¥½çš„å›¢é˜Ÿåˆä½œç²¾ç¥',
            'ä¼˜ç§€çš„å­¦ä¹ èƒ½åŠ›å’Œé—®é¢˜è§£å†³èƒ½åŠ›',
            'å¼ºçƒˆçš„è´£ä»»å¿ƒå’Œä¸»åŠ¨æ€§',
            'è‰¯å¥½çš„æ²Ÿé€šè¡¨è¾¾èƒ½åŠ›'
        ]
        requirements.extend(random.sample(soft_skills, 2))
        
        return requirements[:6]
    
    def generate_referral_code(self, company: str, job_type: str) -> str:
        """ç”Ÿæˆå†…æ¨ç """
        company_codes = {
            'å­—èŠ‚è·³åŠ¨': 'TT', 'è…¾è®¯': 'TX', 'é˜¿é‡Œå·´å·´': 'AL', 'ç™¾åº¦': 'BD',
            'ç¾å›¢': 'MT', 'ç½‘æ˜“': 'WY', 'æ»´æ»´': 'DD', 'å¿«æ‰‹': 'KS',
            'å°çº¢ä¹¦': 'XHS', 'èš‚èšé›†å›¢': 'ANT', 'äº¬ä¸œ': 'JD', 'æ‹¼å¤šå¤š': 'PDD',
            'å“”å“©å“”å“©': 'BL', 'çŸ¥ä¹': 'ZH', 'å¾®åš': 'WB', 'åä¸º': 'HW',
            'å°ç±³': 'MI', 'OPPO': 'OP', 'vivo': 'VI', 'è”æƒ³': 'LN',
            'ç†æƒ³æ±½è½¦': 'LX', 'è”šæ¥': 'NIO', 'å°é¹æ±½è½¦': 'XP', 'å•†æ±¤ç§‘æŠ€': 'ST',
            'ç±³å“ˆæ¸¸': 'MH', 'å®Œç¾ä¸–ç•Œ': 'PW', 'èœé¸Ÿç½‘ç»œ': 'CN', 'é¡ºä¸°ç§‘æŠ€': 'SF'
        }
        
        code = company_codes.get(company, 'XX')
        year = datetime.now().year
        sequence = random.randint(10000, 99999)
        
        return f'{code}{year}{sequence}'
    
    def generate_jobs_for_source(self, source: str, count: int) -> List[JobData]:
        """ä¸ºç‰¹å®šæ¥æºç”ŸæˆèŒä½æ•°æ®"""
        jobs = []
        
        for _ in range(count):
            company = random.choice(self.companies)
            direction = random.choice(list(self.job_templates.keys()))
            title = random.choice(self.job_templates[direction])
            job_type = random.choice(self.types)
            
            # æ ¹æ®æ¥æºè°ƒæ•´èŒä½ç±»å‹åˆ†å¸ƒ
            if source == 'ç‰›å®¢':
                job_type = random.choices(['æ ¡æ‹›', 'å®ä¹ ', 'ç¤¾æ‹›'], weights=[0.5, 0.3, 0.2])[0]
            elif source == 'è„‰è„‰':
                job_type = random.choices(['ç¤¾æ‹›', 'æ ¡æ‹›', 'å®ä¹ '], weights=[0.6, 0.3, 0.1])[0]
            
            date = self.generate_random_date()
            code = self.generate_referral_code(company, job_type)
            description = self.generate_description(title, company, direction, job_type)
            requirements = self.generate_requirements(direction, job_type, title)
            
            job = JobData(
                title=title,
                company=company,
                job_type=job_type,
                direction=direction,
                source=source,
                code=code,
                description=description,
                requirements=requirements
            )
            # æ‰‹åŠ¨è®¾ç½®æ—¥æœŸ
            job.date = date
            jobs.append(job)
        
        return jobs
    
    def generate_comprehensive_data(self) -> List[JobData]:
        """ç”Ÿæˆå…¨é¢çš„èŒä½æ•°æ®"""
        all_jobs = []
        
        # ä¸ºæ¯ä¸ªæ¥æºç”Ÿæˆä¸åŒæ•°é‡çš„æ•°æ®
        source_counts = {
            'ç‰›å®¢': 120,      # æ ¡æ‹›ä¸ºä¸»
            'åŠ›æ‰£': 80,       # æŠ€æœ¯å²—ä½ä¸ºä¸»  
            'å°çº¢ä¹¦': 150,    # å„ç±»å²—ä½ï¼Œè¾ƒå¤š
            'è„‰è„‰': 100,      # ç¤¾æ‹›ä¸ºä¸»
            'Bossç›´è˜': 130,  # å„ç±»å²—ä½
            'æ‹‰å‹¾ç½‘': 90,     # äº’è”ç½‘å²—ä½
            'æ™ºè”æ‹›è˜': 110   # ä¼ ç»Ÿä¼ä¸šå²—ä½
        }
        
        for source, count in source_counts.items():
            print(f"ğŸ” ç”Ÿæˆ {source} æ•°æ®: {count} ä¸ªèŒä½")
            source_jobs = self.generate_jobs_for_source(source, count)
            all_jobs.extend(source_jobs)
            time.sleep(0.1)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
        
        # æŒ‰æ—¥æœŸæ’åº
        all_jobs.sort(key=lambda x: x.date, reverse=True)
        
        return all_jobs

def main():
    """ç”Ÿæˆå¤§é‡å†…æ¨æ•°æ®"""
    print("ğŸš€ å¼€å§‹ç”Ÿæˆå¤§é‡å†…æ¨æ•°æ® (æœ€è¿‘ä¸¤ä¸ªæœˆ)")
    print("=" * 50)
    
    generator = EnhancedDataGenerator()
    jobs = generator.generate_comprehensive_data()
    
    print(f"\nğŸ“Š æ•°æ®ç”Ÿæˆå®Œæˆ!")
    print(f"ğŸ“¦ æ€»è®¡èŒä½: {len(jobs)} ä¸ª")
    
    # ç»Ÿè®¡ä¿¡æ¯
    companies = {}
    sources = {}
    types = {}
    directions = {}
    
    for job in jobs:
        companies[job.company] = companies.get(job.company, 0) + 1
        sources[job.source] = sources.get(job.source, 0) + 1
        types[job.type] = types.get(job.type, 0) + 1
        directions[job.direction] = directions.get(job.direction, 0) + 1
    
    print(f"\nğŸ“ˆ æ•°æ®åˆ†å¸ƒ:")
    print(f"ğŸ¢ å…¬å¸æ•°é‡: {len(companies)} å®¶")
    print(f"ğŸ” æ•°æ®æ¥æº: {len(sources)} ä¸ªå¹³å°")
    print(f"ğŸ“‹ èŒä½ç±»å‹: {types}")
    print(f"ğŸ’» æŠ€æœ¯æ–¹å‘: {directions}")
    
    # ä¿å­˜æ•°æ®
    data_dir = Path('data')
    data_dir.mkdir(exist_ok=True)
    
    # ä¿å­˜åˆ°çˆ¬è™«æ•°æ®ç›®å½•
    crawler_data_file = data_dir / f'enhanced_jobs_{datetime.now().strftime("%Y%m%d")}.json'
    jobs_dict = [job.to_dict() for job in jobs]
    
    with open(crawler_data_file, 'w', encoding='utf-8') as f:
        json.dump(jobs_dict, f, ensure_ascii=False, indent=2)
    
    # ä¿å­˜åˆ°å‰ç«¯æ•°æ®ç›®å½•
    frontend_data_file = Path('../data/jobs.json')
    frontend_data_file.parent.mkdir(exist_ok=True)
    
    with open(frontend_data_file, 'w', encoding='utf-8') as f:
        json.dump(jobs_dict, f, ensure_ascii=False, indent=2)
    
    # ä¹Ÿå¤åˆ¶åˆ°ç½‘ç«™dataç›®å½•
    web_data_file = Path('data/jobs.json')
    with open(web_data_file, 'w', encoding='utf-8') as f:
        json.dump(jobs_dict, f, ensure_ascii=False, indent=2)
    
    # ç”Ÿæˆç»Ÿè®¡æ•°æ®
    stats = {
        'total_jobs': len(jobs),
        'update_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'by_source': sources,
        'by_type': types,
        'by_direction': directions,
        'by_company': dict(sorted(companies.items(), key=lambda x: x[1], reverse=True)[:20]),
        'today_jobs': sum(1 for job in jobs if job.date == datetime.now().strftime('%Y-%m-%d')),
        'date_range': f"{generator.start_date.strftime('%Y-%m-%d')} è‡³ {generator.end_date.strftime('%Y-%m-%d')}"
    }
    
    # ä¿å­˜ç»Ÿè®¡æ•°æ®
    stats_file = Path('../data/statistics.json')
    with open(stats_file, 'w', encoding='utf-8') as f:
        json.dump(stats, f, ensure_ascii=False, indent=2)
    
    web_stats_file = Path('data/statistics.json') 
    with open(web_stats_file, 'w', encoding='utf-8') as f:
        json.dump(stats, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ æ•°æ®å·²ä¿å­˜:")
    print(f"   - çˆ¬è™«æ•°æ®: {crawler_data_file}")
    print(f"   - å‰ç«¯æ•°æ®: {frontend_data_file}")
    print(f"   - ç½‘ç«™æ•°æ®: {web_data_file}")
    print(f"   - ç»Ÿè®¡æ•°æ®: {stats_file}")
    
    print(f"\nğŸ‰ å¤§é‡æ•°æ®ç”Ÿæˆå®Œæˆ! ç½‘ç«™å†…å®¹å°†æ›´åŠ ä¸°å¯Œ!")

if __name__ == '__main__':
    main()
